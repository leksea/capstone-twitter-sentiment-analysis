{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70934233-4e52-4f0f-883b-56cbc48f299c",
      "metadata": {
        "id": "70934233-4e52-4f0f-883b-56cbc48f299c"
      },
      "source": [
        "# Twitter Sentiment Analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d78d833-547c-4b7c-8527-1c64eef0d3cc",
      "metadata": {
        "id": "3d78d833-547c-4b7c-8527-1c64eef0d3cc"
      },
      "source": [
        "## Business Problem.\n",
        "\n",
        "We want to analyze a COVID-19 Twitter dataset to understand how positive and negative trends spread after news announcements. Additionally, we want to use a bot detection algorithm to determine what percentage of each sentiment is made up of bots and how this affects the general sentiment of the public (non-bots).\n",
        "\n",
        "Key Questions:\n",
        "\n",
        "How do positive and negative sentiments spread among users after a news announcement related to COVID-19?\n",
        "What proportion of tweets in each sentiment category (positive/negative/neutral) come from bots?\n",
        "How do bots influence the general sentiment of non-bot users?\n",
        "Purpose:\n",
        "\n",
        "Help media outlets measure the impact of their announcements on public sentiment.\n",
        "Assist public health agencies in identifying misinformation or bot-driven content to improve communication strategies.\n",
        "Support social media platforms in detecting and limiting bot activity that could distort public opinion.\n",
        "Goals:\n",
        "\n",
        "Track sentiment trends over time.\n",
        "Quantify bot participation in each sentiment category.\n",
        "Measure the influence of bots on genuine public sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets location and download instructions.\n",
        "\n",
        "1. [Covid-19 Twitter Dataset](https://www.kaggle.com/datasets/arunavakrchakraborty/covid19-twitter-dataset/data)\n",
        "\n",
        "2. [Twitter Bots Accounts.](https://www.kaggle.com/datasets/davidmartngutirrez/twitter-bots-accounts)\n",
        "\n",
        "* Place datasets into ```Data``` folder if running the notebook locally.\n",
        "* Upload the files into ```/content``` root file folder of Colab environment."
      ],
      "metadata": {
        "id": "lSJyODVEaJZs"
      },
      "id": "lSJyODVEaJZs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the required modules.\n",
        "\n",
        "We'll start with installing the requirements [available here](https://github.com/leksea/capstone-twitter-sentiment-analysis/blob/main/requirements.txt)."
      ],
      "metadata": {
        "id": "fQwFcnPjZpd9"
      },
      "id": "fQwFcnPjZpd9"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/leksea/capstone-twitter-sentiment-analysis/main/requirements.txt\n",
        "!pip install -r 'requirements.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st62fukEaHir",
        "outputId": "65710a5e-2ff0-4be9-bdcc-ab637a978181"
      },
      "id": "st62fukEaHir",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-26 02:08:36--  https://raw.githubusercontent.com/leksea/capstone-twitter-sentiment-analysis/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]      98  --.-KB/s    in 0s      \n",
            "\n",
            "2024-12-26 02:08:37 (5.10 MB/s) - ‘requirements.txt’ saved [98/98]\n",
            "\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.8.1)\n",
            "Collecting cartopy (from -r requirements.txt (line 7))\n",
            "  Downloading Cartopy-0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.32.3)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.19.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (3.9.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (11.0.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from branca->-r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: shapely>=1.8 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 7)) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 7)) (3.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (2024.12.14)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium->-r requirements.txt (line 9)) (2024.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 10)) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 10)) (2024.11.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=3->branca->-r requirements.txt (line 6)) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n",
            "Downloading Cartopy-0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing modules."
      ],
      "metadata": {
        "id": "Zd0e2IvvfuDJ"
      },
      "id": "Zd0e2IvvfuDJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import string\n",
        "import re\n",
        "import glob\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import branca.colormap as cm\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
        "import requests\n",
        "import folium\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "import branca.colormap\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm, notebook\n",
        "%matplotlib inline\n",
        "# stop words for tokenizer\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "py58BnTUdbsd",
        "outputId": "208b1b40-d5cb-41f9-8ab5-9119a89f1ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "py58BnTUdbsd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading The Covid-19 Twitter Datasets."
      ],
      "metadata": {
        "id": "hnoqoMM-gr0F"
      },
      "id": "hnoqoMM-gr0F"
    },
    {
      "cell_type": "code",
      "source": [
        "# Supplemental function to determine data directory\n",
        "# Input: none\n",
        "# Output: Data directory, depending on runtime environment.\n",
        "\n",
        "def determine_data_dir():\n",
        "    \"\"\"\n",
        "    Determines the data directory based on the execution environment:\n",
        "    - Local: Uses 'Data' directory in the current working directory.\n",
        "    - Cloud (e.g., Google Colab): Uses '/content' as the data directory.\n",
        "\n",
        "    Returns:\n",
        "        str: Path to the appropriate data directory.\n",
        "    \"\"\"\n",
        "    if 'COLAB_GPU' in os.environ:  # Check if running in Google Colab\n",
        "        data_dir = \"/content\"\n",
        "        print(f\"Running in Google Colab. Using data directory: {data_dir}\")\n",
        "    else:\n",
        "        data_dir = os.path.join(os.getcwd(), \"Data\")\n",
        "        print(f\"Running locally. Using data directory: {data_dir}\")\n",
        "\n",
        "        # Ensure the 'Data' directory exists locally\n",
        "        if not os.path.isdir(data_dir):\n",
        "            print(f\"The directory '{data_dir}' does not exist. Please create it and place the data files there.\")\n",
        "            raise FileNotFoundError(f\"'{data_dir}' directory is required for local execution.\")\n",
        "\n",
        "    return data_dir"
      ],
      "metadata": {
        "id": "dLmUhcBtfxFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0722a530-c33c-482d-ca73-68d51cc389e7"
      },
      "id": "dLmUhcBtfxFS",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab. Using data directory: /content\n",
            "Found 3 files: ['/content/Covid-19 Twitter Dataset (Apr-Jun 2020).csv', '/content/Covid-19 Twitter Dataset (Apr-Jun 2021).csv', '/content/Covid-19 Twitter Dataset (Aug-Sep 2020).csv']\n",
            "Data loaded successfully with 411887 rows and 17 columns.\n",
            "             id  created_at  \\\n",
            "0  1.250000e+18  2020-04-19   \n",
            "1  1.250000e+18  2020-04-19   \n",
            "2  1.250000e+18  2020-04-19   \n",
            "3  1.250000e+18  2020-04-19   \n",
            "4  1.250000e+18  2020-04-19   \n",
            "\n",
            "                                              source  \\\n",
            "0  <a href=\"http://twitter.com/download/android\" ...   \n",
            "1  <a href=\"http://twitter.com/download/android\" ...   \n",
            "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
            "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
            "4  <a href=\"http://twitter.com/download/android\" ...   \n",
            "\n",
            "                                       original_text lang  favorite_count  \\\n",
            "0  RT @GlblCtzn: .@priyankachopra is calling on l...   en             0.0   \n",
            "1  RT @OGSG_Official: OGUN STATE SUPPORT FOR CBN-...   en             0.0   \n",
            "2  RT @AdvoBarryRoux: These 5 police officials ba...   en             0.0   \n",
            "3  RT @MobilePunch: COVID-19: Oyo discharges two ...   en             0.0   \n",
            "4  My Condolences to the Family of those who did ...   en             0.0   \n",
            "\n",
            "   retweet_count  original_author  hashtags             user_mentions  \\\n",
            "0           31.0          RJIshak       NaN  GlblCtzn, priyankachopra   \n",
            "1           61.0   makinwaoluwole       NaN             OGSG_Official   \n",
            "2            1.0         TembeAmu       NaN             AdvoBarryRoux   \n",
            "3            0.0       ilyasrabiu       NaN               MobilePunch   \n",
            "4        13869.0  bucketeconomist  Covid_19                       NaN   \n",
            "\n",
            "                    place                                        clean_tweet  \\\n",
            "0  Jakarta Capital Region  call leader help protect refuge covid19 provid...   \n",
            "1                 Nigeria  ogun state support cbn nirsal covid19 target c...   \n",
            "2                     NaN  polic offici base namahadi polic station busi ...   \n",
            "3          Lagos, Nigeria                   covid19 oyo discharg two patient   \n",
            "4                     NaN                               condol famili surviv   \n",
            "\n",
            "   compound  neg    neu    pos sentiment  \n",
            "0    0.8176  0.0  0.452  0.548       pos  \n",
            "1    0.6486  0.0  0.602  0.398       pos  \n",
            "2    0.2732  0.0  0.851  0.149       pos  \n",
            "3    0.0000  0.0  1.000  0.000       neu  \n",
            "4    0.0000  0.0  1.000  0.000       neu  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the files\n",
        "# Determine the data directory\n",
        "data_dir = determine_data_dir()\n",
        "\n",
        "# Step 1: Locate all CSV files in the determined directory\n",
        "files_pattern = os.path.join(data_dir, \"*.csv\")\n",
        "files = glob.glob(files_pattern)\n",
        "\n",
        "# Step 2: Check if files are found\n",
        "if not files:\n",
        "    print(f\"No CSV files found in directory: {data_dir}\")\n",
        "else:\n",
        "    print(f\"Found {len(files)} files: {files}\")\n",
        "\n",
        "    # Step 3: Load and concatenate the files into a single DataFrame\n",
        "    data = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
        "    print(f\"Data loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "    print(data.head())"
      ],
      "metadata": {
        "id": "Gn7kjSy5DgOe",
        "outputId": "5ce1a73f-9e78-424d-d759-040a115e6738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Gn7kjSy5DgOe",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab. Using data directory: /content\n",
            "Found 3 files: ['/content/Covid-19 Twitter Dataset (Apr-Jun 2020).csv', '/content/Covid-19 Twitter Dataset (Apr-Jun 2021).csv', '/content/Covid-19 Twitter Dataset (Aug-Sep 2020).csv']\n",
            "Data loaded successfully with 411887 rows and 17 columns.\n",
            "             id  created_at  \\\n",
            "0  1.250000e+18  2020-04-19   \n",
            "1  1.250000e+18  2020-04-19   \n",
            "2  1.250000e+18  2020-04-19   \n",
            "3  1.250000e+18  2020-04-19   \n",
            "4  1.250000e+18  2020-04-19   \n",
            "\n",
            "                                              source  \\\n",
            "0  <a href=\"http://twitter.com/download/android\" ...   \n",
            "1  <a href=\"http://twitter.com/download/android\" ...   \n",
            "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
            "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
            "4  <a href=\"http://twitter.com/download/android\" ...   \n",
            "\n",
            "                                       original_text lang  favorite_count  \\\n",
            "0  RT @GlblCtzn: .@priyankachopra is calling on l...   en             0.0   \n",
            "1  RT @OGSG_Official: OGUN STATE SUPPORT FOR CBN-...   en             0.0   \n",
            "2  RT @AdvoBarryRoux: These 5 police officials ba...   en             0.0   \n",
            "3  RT @MobilePunch: COVID-19: Oyo discharges two ...   en             0.0   \n",
            "4  My Condolences to the Family of those who did ...   en             0.0   \n",
            "\n",
            "   retweet_count  original_author  hashtags             user_mentions  \\\n",
            "0           31.0          RJIshak       NaN  GlblCtzn, priyankachopra   \n",
            "1           61.0   makinwaoluwole       NaN             OGSG_Official   \n",
            "2            1.0         TembeAmu       NaN             AdvoBarryRoux   \n",
            "3            0.0       ilyasrabiu       NaN               MobilePunch   \n",
            "4        13869.0  bucketeconomist  Covid_19                       NaN   \n",
            "\n",
            "                    place                                        clean_tweet  \\\n",
            "0  Jakarta Capital Region  call leader help protect refuge covid19 provid...   \n",
            "1                 Nigeria  ogun state support cbn nirsal covid19 target c...   \n",
            "2                     NaN  polic offici base namahadi polic station busi ...   \n",
            "3          Lagos, Nigeria                   covid19 oyo discharg two patient   \n",
            "4                     NaN                               condol famili surviv   \n",
            "\n",
            "   compound  neg    neu    pos sentiment  \n",
            "0    0.8176  0.0  0.452  0.548       pos  \n",
            "1    0.6486  0.0  0.602  0.398       pos  \n",
            "2    0.2732  0.0  0.851  0.149       pos  \n",
            "3    0.0000  0.0  1.000  0.000       neu  \n",
            "4    0.0000  0.0  1.000  0.000       neu  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsrDMCYiEfUL"
      },
      "id": "tsrDMCYiEfUL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}